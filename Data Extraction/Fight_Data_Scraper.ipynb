{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "154c3f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import concurrent.futures\n",
    "import threading\n",
    "from typing import Dict, List\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import requests\n",
    "from typing import Tuple\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE_PATH = Path(os.getcwd()) / \"data\"\n",
    "EVENT_AND_FIGHT_LINKS_PICKLE = BASE_PATH / \"event_and_fight_links.pickle\"\n",
    "PAST_EVENT_LINKS_PICKLE = BASE_PATH / \"past_event_links.pickle\"\n",
    "PAST_FIGHTER_LINKS_PICKLE = BASE_PATH / \"past_fighter_links.pickle\"\n",
    "SCRAPED_FIGHTER_DATA_DICT_PICKLE = BASE_PATH / \"scraped_fighter_data_dict.pickle\"\n",
    "NEW_EVENT_AND_FIGHTS = BASE_PATH / \"new_fight_data.csv\"\n",
    "TOTAL_EVENT_AND_FIGHTS = BASE_PATH / \"raw_total_fight_data.csv\"\n",
    "PREPROCESSED_DATA = BASE_PATH / \"preprocessed_data.csv\"\n",
    "FIGHTER_DETAILS = BASE_PATH / \"raw_fighter_details.csv\"\n",
    "UFC_DATA = BASE_PATH / \"data.csv\"\n",
    "\n",
    "\n",
    "\n",
    "def make_soup(url: str) -> BeautifulSoup:\n",
    "    source_code = requests.get(url, allow_redirects=False)\n",
    "    plain_text = source_code.text.encode(\"ascii\", \"replace\")\n",
    "    return BeautifulSoup(plain_text, \"html.parser\")\n",
    "\n",
    "\n",
    "def print_progress(\n",
    "    iteration: int,\n",
    "    total: int,\n",
    "    prefix: str = \"\",\n",
    "    suffix: str = \"\",\n",
    "    decimals: int = 1,\n",
    "    bar_length: int = 50,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        bar_length  - Optional  : character length of bar (Int)\n",
    "    \"\"\"\n",
    "    percents = f\"{100 * (iteration / float(total)):.2f}\"\n",
    "    filled_length = int(round(bar_length * iteration / float(total)))\n",
    "    bar = f'{\"█\" * filled_length}{\"-\" * (bar_length - filled_length)}'\n",
    "\n",
    "    sys.stdout.write(f\"\\r{prefix} |{bar}| {percents}% {suffix}\")\n",
    "\n",
    "    if iteration == total:\n",
    "        sys.stdout.write(\"\\n\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class UFCLinks:\n",
    "    def __init__(\n",
    "        self, all_events_url=\"http://ufcstats.com/statistics/events/completed?page=all\"\n",
    "    ):\n",
    "        self.all_events_url = all_events_url\n",
    "        self.PAST_EVENT_LINKS_PICKLE_PATH = PAST_EVENT_LINKS_PICKLE\n",
    "        self.EVENT_AND_FIGHT_LINKS_PICKLE_PATH = EVENT_AND_FIGHT_LINKS_PICKLE\n",
    "        self.new_event_links, self.all_event_links = self._get_updated_event_links()\n",
    "\n",
    "    def _get_updated_event_links(self) -> Tuple[List[str], List[str]]:\n",
    "        all_event_links = []\n",
    "        soup = make_soup(self.all_events_url)\n",
    "\n",
    "        for link in soup.findAll(\"td\", {\"class\": \"b-statistics__table-col\"}):\n",
    "            for href in link.findAll(\"a\"):\n",
    "                foo = href.get(\"href\")\n",
    "                all_event_links.append(foo)\n",
    "\n",
    "        if not self.PAST_EVENT_LINKS_PICKLE_PATH.exists():\n",
    "            # if no past event links are present, then there are no new event links\n",
    "            new_event_links = []\n",
    "        else:\n",
    "            # get past event links\n",
    "            with open(self.PAST_EVENT_LINKS_PICKLE_PATH.as_posix(), \"rb\") as pickle_in:\n",
    "                past_event_links = pickle.load(pickle_in)\n",
    "\n",
    "            # Find links of the newer events\n",
    "            new_event_links = list(set(all_event_links) - set(past_event_links))\n",
    "\n",
    "        # dump all_event_links as PAST_EVENT_LINKS\n",
    "        with open(self.PAST_EVENT_LINKS_PICKLE_PATH.as_posix(), \"wb\") as f:\n",
    "            pickle.dump(all_event_links, f)\n",
    "\n",
    "        return new_event_links, all_event_links\n",
    "\n",
    "    def get_event_and_fight_links(self) -> (Dict, Dict):\n",
    "        def get_fight_links(event_links: List[str]) -> Dict[str, List[str]]:\n",
    "            event_and_fight_links = {}\n",
    "\n",
    "            l = len(event_links)\n",
    "            print(\"Scraping event and fight links: \")\n",
    "            print_progress(0, l, prefix=\"Progress:\", suffix=\"Complete\")\n",
    "\n",
    "            for index, link in enumerate(event_links):\n",
    "                event_fights = []\n",
    "                soup = make_soup(link)\n",
    "                for row in soup.findAll(\n",
    "                    \"tr\",\n",
    "                    {\n",
    "                        \"class\": \"b-fight-details__table-row b-fight-details__table-row__hover js-fight-details-click\"\n",
    "                    },\n",
    "                ):\n",
    "                    href = row.get(\"data-link\")\n",
    "                    event_fights.append(href)\n",
    "                event_and_fight_links[link] = event_fights\n",
    "\n",
    "                print_progress(index + 1, l, prefix=\"Progress:\", suffix=\"Complete\")\n",
    "\n",
    "            return event_and_fight_links\n",
    "\n",
    "        new_events_and_fight_links = {}\n",
    "        if self.EVENT_AND_FIGHT_LINKS_PICKLE_PATH.exists():\n",
    "            if not self.new_event_links:\n",
    "                with open(\n",
    "                    self.EVENT_AND_FIGHT_LINKS_PICKLE_PATH.as_posix(), \"rb\"\n",
    "                ) as pickle_in:\n",
    "                    all_events_and_fight_links = pickle.load(pickle_in)\n",
    "\n",
    "                return new_events_and_fight_links, all_events_and_fight_links\n",
    "            else:\n",
    "                new_events_and_fight_links = get_fight_links(self.new_event_links)\n",
    "\n",
    "        all_events_and_fight_links = get_fight_links(self.all_event_links)\n",
    "        with open(self.EVENT_AND_FIGHT_LINKS_PICKLE_PATH.as_posix(), \"wb\") as f:\n",
    "            pickle.dump(all_events_and_fight_links, f)\n",
    "\n",
    "        return new_events_and_fight_links, all_events_and_fight_links\n",
    "    \n",
    "    \n",
    "    \n",
    "class FightDataScraper:\n",
    "    def __init__(self):\n",
    "        self.HEADER: str = \"R_fighter;B_fighter;R_KD;B_KD;R_SIG_STR.;B_SIG_STR.\\\n",
    ";R_SIG_STR_pct;B_SIG_STR_pct;R_TOTAL_STR.;B_TOTAL_STR.;R_TD;B_TD;R_TD_pct\\\n",
    ";B_TD_pct;R_SUB_ATT;B_SUB_ATT;R_REV;B_REV;R_CTRL;B_CTRL;R_HEAD;B_HEAD;R_BODY\\\n",
    ";B_BODY;R_LEG;B_LEG;R_DISTANCE;B_DISTANCE;R_CLINCH;B_CLINCH;R_GROUND;B_GROUND\\\n",
    ";win_by;last_round;last_round_time;Format;Referee;date;location;Fight_type;Winner\\n\"\n",
    "\n",
    "        self.NEW_EVENT_AND_FIGHTS_PATH = NEW_EVENT_AND_FIGHTS\n",
    "        self.TOTAL_EVENT_AND_FIGHTS_PATH = TOTAL_EVENT_AND_FIGHTS\n",
    "\n",
    "    def create_fight_data_csv(self) -> None:\n",
    "        print(\"Scraping links!\")\n",
    "\n",
    "        ufc_links = UFCLinks()\n",
    "        new_events_and_fight_links, all_events_and_fight_links = (\n",
    "            ufc_links.get_event_and_fight_links()\n",
    "        )\n",
    "        print(\"Successfully scraped and saved event and fight links!\\n\")\n",
    "        print(\"Now, scraping event and fight data!\\n\")\n",
    "\n",
    "        if not new_events_and_fight_links:\n",
    "            if self.TOTAL_EVENT_AND_FIGHTS_PATH.exists():\n",
    "                print(f'No new fight data to scrape at the moment, loaded existing data from {self.TOTAL_EVENT_AND_FIGHTS_PATH}.')\n",
    "                return\n",
    "            else:\n",
    "                self._scrape_raw_fight_data(\n",
    "                    all_events_and_fight_links,\n",
    "                    filepath=self.TOTAL_EVENT_AND_FIGHTS_PATH,\n",
    "                )\n",
    "        else:\n",
    "            self._scrape_raw_fight_data(\n",
    "                new_events_and_fight_links, filepath=self.NEW_EVENT_AND_FIGHTS_PATH\n",
    "            )\n",
    "\n",
    "            new_event_and_fights_data = pd.read_csv(self.NEW_EVENT_AND_FIGHTS_PATH)\n",
    "            old_event_and_fights_data = pd.read_csv(self.TOTAL_EVENT_AND_FIGHTS_PATH)\n",
    "\n",
    "            assert len(new_event_and_fights_data.columns) == len(\n",
    "                old_event_and_fights_data.columns\n",
    "            )\n",
    "\n",
    "            new_event_and_fights_data = new_event_and_fights_data[\n",
    "                list(old_event_and_fights_data.columns)\n",
    "            ]\n",
    "\n",
    "            latest_total_fight_data = new_event_and_fights_data.append(\n",
    "                old_event_and_fights_data, ignore_index=True\n",
    "            )\n",
    "            latest_total_fight_data.to_csv(self.TOTAL_EVENT_AND_FIGHTS_PATH, index=None)\n",
    "\n",
    "            os.remove(self.NEW_EVENT_AND_FIGHTS_PATH)\n",
    "            print(\"Removed new event and fight files\")\n",
    "\n",
    "        print(\"Successfully scraped and saved ufc fight data!\\n\")\n",
    "\n",
    "    def _scrape_raw_fight_data(\n",
    "        self, event_and_fight_links: Dict[str, List[str]], filepath\n",
    "    ):\n",
    "        if filepath.exists():\n",
    "            print(f'File {filepath} already exists, overwriting.')\n",
    "\n",
    "        total_stats = FightDataScraper._get_total_fight_stats(event_and_fight_links)\n",
    "        with open(filepath.as_posix(), \"wb\") as file:\n",
    "            file.write(bytes(self.HEADER, encoding=\"ascii\", errors=\"ignore\"))\n",
    "            file.write(bytes(total_stats, encoding=\"ascii\", errors=\"ignore\"))\n",
    "\n",
    "    def _get_fight_stats_task(self, fight, event_info):\n",
    "        #print(threading.get_native_id())\n",
    "        total_fight_stats = \"\"\n",
    "        try:\n",
    "            fight_soup = make_soup(fight)\n",
    "            fight_stats = FightDataScraper._get_fight_stats(fight_soup)\n",
    "            fight_details = FightDataScraper._get_fight_details(fight_soup)\n",
    "            result_data = FightDataScraper._get_fight_result_data(fight_soup)\n",
    "            total_fight_stats = (\n",
    "                    fight_stats\n",
    "                    + \";\"\n",
    "                    + fight_details\n",
    "                    + \";\"\n",
    "                    + event_info\n",
    "                    + \";\"\n",
    "                    + result_data\n",
    "            )\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            #print(\"Error getting fight stats, \" + str(e))\n",
    "\n",
    "        return total_fight_stats\n",
    "\n",
    "    @classmethod\n",
    "    def _get_total_fight_stats(cls, event_and_fight_links: Dict[str, List[str]]) -> str:\n",
    "        total_stats = \"\"\n",
    "\n",
    "        l = len(event_and_fight_links)\n",
    "        print(f'Scraping data for {l} fights: ')\n",
    "        print_progress(0, l, prefix=\"Progress:\", suffix=\"Complete\")\n",
    "\n",
    "        for index, (event, fights) in enumerate(event_and_fight_links.items()):\n",
    "            event_soup = make_soup(event)\n",
    "            event_info = FightDataScraper._get_event_info(event_soup)\n",
    "\n",
    "            # Get data for each fight in the event in parallel.\n",
    "            with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:\n",
    "                futures = []\n",
    "                for fight in fights:\n",
    "                    futures.append(executor.submit(FightDataScraper._get_fight_stats_task, self=cls, fight=fight, event_info=event_info))\n",
    "                for future in concurrent.futures.as_completed(futures):\n",
    "                    fighter_stats = future.result()\n",
    "                    if fighter_stats != \"\":\n",
    "                        if total_stats == \"\":\n",
    "                            total_stats = fighter_stats\n",
    "                        else:\n",
    "                            total_stats = total_stats + \"\\n\" + fighter_stats\n",
    "                    print_progress(index + 1, l, prefix=\"Progress:\", suffix=\"Complete\")\n",
    "\n",
    "        return total_stats\n",
    "\n",
    "    @classmethod\n",
    "    def _get_fight_stats(cls, fight_soup: BeautifulSoup) -> str:\n",
    "        tables = fight_soup.findAll(\"tbody\")\n",
    "        total_fight_data = [tables[0], tables[2]]\n",
    "        fight_stats = []\n",
    "        for table in total_fight_data:\n",
    "            row = table.find(\"tr\")\n",
    "            stats = \"\"\n",
    "            for data in row.findAll(\"td\"):\n",
    "                if stats == \"\":\n",
    "                    stats = data.text\n",
    "                else:\n",
    "                    stats = stats + \",\" + data.text\n",
    "            fight_stats.append(\n",
    "                stats.replace(\"  \", \"\")\n",
    "                .replace(\"\\n\\n\", \"\")\n",
    "                .replace(\"\\n\", \",\")\n",
    "                .replace(\", \", \",\")\n",
    "                .replace(\" ,\", \",\")\n",
    "            )\n",
    "\n",
    "        fight_stats[1] = \";\".join(fight_stats[1].split(\",\")[6:])\n",
    "        fight_stats[0] = \";\".join(fight_stats[0].split(\",\"))\n",
    "        fight_stats = \";\".join(fight_stats)\n",
    "        return fight_stats\n",
    "\n",
    "    @classmethod\n",
    "    def _get_fight_details(cls, fight_soup: BeautifulSoup) -> str:\n",
    "        columns = \"\"\n",
    "        for div in fight_soup.findAll(\"div\", {\"class\": \"b-fight-details__content\"}):\n",
    "            for col in div.findAll(\"p\", {\"class\": \"b-fight-details__text\"}):\n",
    "                if columns == \"\":\n",
    "                    columns = col.text\n",
    "                else:\n",
    "                    columns = columns + \",\" + (col.text)\n",
    "\n",
    "        columns = (\n",
    "            columns.replace(\"  \", \"\")\n",
    "            .replace(\"\\n\\n\\n\\n\", \",\")\n",
    "            .replace(\"\\n\", \"\")\n",
    "            .replace(\", \", \",\")\n",
    "            .replace(\" ,\", \",\")\n",
    "            .replace(\"Method: \", \"\")\n",
    "            .replace(\"Round:\", \"\")\n",
    "            .replace(\"Time:\", \"\")\n",
    "            .replace(\"Time format:\", \"\")\n",
    "            .replace(\"Referee:\", \"\")\n",
    "        )\n",
    "\n",
    "        fight_details = \";\".join(columns.split(\",\")[:5])\n",
    "\n",
    "        return fight_details\n",
    "\n",
    "    @classmethod\n",
    "    def _get_event_info(cls, event_soup: BeautifulSoup) -> str:\n",
    "        event_info = \"\"\n",
    "        for info in event_soup.findAll(\"li\", {\"class\": \"b-list__box-list-item\"}):\n",
    "            if event_info == \"\":\n",
    "                event_info = info.text\n",
    "            else:\n",
    "                event_info = event_info + \";\" + info.text\n",
    "\n",
    "        event_info = \";\".join(\n",
    "            event_info.replace(\"Date:\", \"\")\n",
    "            .replace(\"Location:\", \"\")\n",
    "            .replace(\"Attendance:\", \"\")\n",
    "            .replace(\"\\n\", \"\")\n",
    "            .replace(\"  \", \"\")\n",
    "            .split(\";\")[:2]\n",
    "        )\n",
    "\n",
    "        return event_info\n",
    "\n",
    "    @classmethod\n",
    "    def _get_fight_result_data(cls, fight_soup: BeautifulSoup) -> str:\n",
    "        winner = \"\"\n",
    "        for div in fight_soup.findAll(\"div\", {\"class\": \"b-fight-details__person\"}):\n",
    "            if (\n",
    "                div.find(\n",
    "                    \"i\",\n",
    "                    {\n",
    "                        \"class\": \"b-fight-details__person-status b-fight-details__person-status_style_green\"\n",
    "                    },\n",
    "                )\n",
    "                is not None\n",
    "            ):\n",
    "                winner = (\n",
    "                    div.find(\"h3\", {\"class\": \"b-fight-details__person-name\"})\n",
    "                    .text.replace(\" \\n\", \"\")\n",
    "                    .replace(\"\\n\", \"\")\n",
    "                )\n",
    "\n",
    "        fight_type = (\n",
    "            fight_soup.find(\"i\", {\"class\": \"b-fight-details__fight-title\"})\n",
    "            .text.replace(\"  \", \"\")\n",
    "            .replace(\"\\n\", \"\")\n",
    "        )\n",
    "\n",
    "        return fight_type + \";\" + winner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44181436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating fight data \n",
      "\n",
      "Scraping links!\n",
      "Successfully scraped and saved event and fight links!\n",
      "\n",
      "Now, scraping event and fight data!\n",
      "\n",
      "Scraping data for 676 fights: \n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n",
      "Progress: |██████████████████████████████████████████████████| 100.00% Complete\n",
      "Successfully scraped and saved ufc fight data!\n",
      "\n",
      "elapsed seconds = 983.46\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time_start = time.time()\n",
    "print(\"Creating fight data \\n\")\n",
    "fight_data_scraper = FightDataScraper()\n",
    "fight_data_scraper.create_fight_data_csv()  # Scrapes raw ufc fight data from website\n",
    "print(f'elapsed seconds = {(time.time() - time_start):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c61677d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
